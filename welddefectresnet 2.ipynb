{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf #tf 2.0.0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler # import the scaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# Scikit learn for preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Image `Augmentation` for Increasing Dataset (Run Augmentation.py )\n",
    "\n",
    "# ImageDataGenerator (in-place augmentation)\n",
    "train_data_gen = ImageDataGenerator(rotation_range=50,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    zoom_range=0.3,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    fill_mode='constant',\n",
    "                                    cval=0,\n",
    "                                    rescale=1./255)\n",
    "valid_data_gen = ImageDataGenerator(rotation_range=45,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    zoom_range=0.3,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    fill_mode='constant',\n",
    "                                    cval=0,\n",
    "                                    rescale=1./255)\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "dataset_dir = os.path.join('F:/GPU3/dataset11', \"\")\n",
    "\n",
    "#dataset_dir = \"E:/Progs/Restore/ManuscriptDataset/dataset11\"\n",
    "\n",
    "Batch_size =32\n",
    "img_h = 512\n",
    "img_w = 512\n",
    "num_classes=4\n",
    "n_epoch = 60\n",
    "\n",
    "classes = ['crack', # 0\n",
    "            'lackoffusion', # 1\n",
    "            'porosity', # 2\n",
    "            'slaginclusion', # 3\n",
    "           ]\n",
    "\n",
    "# Training\n",
    "SEED = 42\n",
    "#SEED = 1234\n",
    "tf.random.set_seed(SEED) \n",
    "\n",
    "# initialize the data and labels\n",
    "# x_train = []\n",
    "# y_train = []\n",
    "# x_test = []\n",
    "# y_test = []\n",
    "\n",
    "\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "train_gen = train_data_gen.flow_from_directory(training_dir,\n",
    "                                               target_size=(512, 512),\n",
    "                                               batch_size=Batch_size,\n",
    "                                               classes=classes,\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               seed=SEED)  # targets are directly converted into one-hot vectors\n",
    "\n",
    "\n",
    "# Validation\n",
    "valid_dir = os.path.join(dataset_dir, 'testing')\n",
    "valid_gen = valid_data_gen.flow_from_directory(valid_dir,\n",
    "                                           target_size=(512, 512),\n",
    "                                           batch_size=Batch_size, \n",
    "                                           classes=classes,\n",
    "                                           class_mode='categorical',\n",
    "                                           shuffle=False,\n",
    "                                           seed=SEED)\n",
    "# Test\n",
    "test_dir = os.path.join(dataset_dir, 'testing')\n",
    "test_gen = test_data_gen.flow_from_directory(test_dir,\n",
    "                                             target_size=(512, 512),\n",
    "                                             batch_size=Batch_size,\n",
    "                                             classes=classes,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=False,\n",
    "                                             seed=SEED)\n",
    "\n",
    "                                \n",
    "print('Train gen =',train_gen.n)\n",
    "train_gen.reset()\n",
    "x_train, y_train = next(train_gen)\n",
    "for i in tqdm(range(int((train_gen.n)/Batch_size))): #1st batch is already fetched before the for loop.\n",
    "  img, label = next(train_gen)\n",
    "  x_train = np.append(x_train, img, axis=0 )\n",
    "  y_train = np.append(y_train, label, axis=0)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "valid_gen.reset()\n",
    "x_test, y_test = next(valid_gen)\n",
    "for i in tqdm(range(int((valid_gen.n)/Batch_size))): #1st batch is already fetched before the for loop.\n",
    "  img, label = next(valid_gen)\n",
    "  x_test = np.append(x_test, img, axis=0 )\n",
    "  y_test = np.append(y_test, label, axis=0)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "#print('Train size = ',x_train.shape,\" \",y_train.shape)\n",
    "#print('Test size = ',x_test.shape,\" \",y_test.shape)\n",
    "# #Visualization data\n",
    "# CLASS_NAMES = np.array(['devanagari','nandinagiri', 'newari','sharda'], dtype='<U10')\n",
    "\n",
    "\n",
    "# def show_batch(image_batch, label_batch):\n",
    "#   plt.figure(figsize=(25,20))\n",
    "#   for n in range(8):\n",
    "#       ax = plt.subplot(1,8,n+1)\n",
    "#       plt.imshow(image_batch[n])\n",
    "#       plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "#       plt.axis('off')\n",
    "      \n",
    "# image_batch, label_batch = next(train_gen)\n",
    "# show_batch(image_batch, label_batch)\n",
    "\n",
    "\n",
    "# ResNet152V2 Model\n",
    "ResNet_model = tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "\n",
    "# The last 15 layers fine tune\n",
    "# for layer in ResNet_model.layers[:-15]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# x = ResNet_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Flatten()(x)\n",
    "# #x = Dense(units=2048, activation='relu')(x)\n",
    "# #x = Dropout(0.25)(x)\n",
    "# x = Dense(units=1024, activation='relu')(x)\n",
    "# #x = Dropout(0.50)(x)\n",
    "# output  = Dense(units=num_classes, activation='softmax')(x)\n",
    "# model = Model(ResNet_model.input, output)\n",
    "\n",
    "# The last 15 layers fine tune\n",
    "for layer in ResNet_model.layers[:-15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = ResNet_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "output  = Dense(units=num_classes, activation='softmax')(x)\n",
    "model = Model(ResNet_model.input, output)\n",
    "print(\"Successfully built the ResNet Model!\")\n",
    "print(model.summary())\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "#loss = tf.keras.losses.KLDivergence()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics= ['accuracy'])\n",
    "print(\"Model Compilation completed!\")\n",
    "\n",
    "mc = ModelCheckpoint('E:/Progs/Restore/best_modelresnet8.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "es=EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)\n",
    "\n",
    "# lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "#lrr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                        # patience=3, \n",
    "                        # verbose=1, \n",
    "                        # factor=0.4, \n",
    "                        # min_lr=0.0001)\n",
    "\n",
    "\n",
    "callbacks = [mc, es]\n",
    "\n",
    "# model fit_generator\n",
    "nb_train_samples = 1665\n",
    "nb_validation_samples = 417\n",
    "\n",
    "STEP_SIZE_TRAIN=nb_train_samples // Batch_size\n",
    "STEP_SIZE_VALID=nb_validation_samples//Batch_size\n",
    "\n",
    "# STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
    "# STEP_SIZE_VALID=valid_gen.n//valid_gen.batch_size\n",
    "\n",
    "import time \n",
    "tstart = time.time()\n",
    "transfer_learning_history = model.fit_generator(generator=train_gen,\n",
    "                   steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                   validation_data=valid_gen,\n",
    "                   validation_steps=STEP_SIZE_VALID,\n",
    "                   epochs=n_epoch,\n",
    "                   #callbacks=[mc,es]\n",
    "                   callbacks=callbacks,\n",
    "                  \n",
    "                    \n",
    ")\n",
    "\n",
    "tend = time.time()\n",
    "elapsed = (tend - tstart)/60\n",
    "print(\"Model trained Successfully : Took - {} mins!\".format(elapsed))\n",
    "\n",
    "# model evaluate with validation set\n",
    "scores = model.evaluate(valid_gen,verbose=0)\n",
    "\n",
    "#print(transfer_learning_history.history.keys())\n",
    "\n",
    "print(\"Test Loss Value: %.2f%%\" % (scores[0]*100))\n",
    "print(\"Test Accuracy Value:  %.2f%%\"  % (scores[1]*100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
